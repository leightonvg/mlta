{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to reproduce the MLTA case study results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results were created using Win10, an AMD RYZEN 5 3600XT with 32GB RAM (4 x 8GB of Crucial Ballistix BL2K8G36C16U4B 3600 MHz with CL16 timings (i.e. overclocked to 3600Mhz in the bios)), and a fast NMVE SSD (Samsung 980 M.2 NVME 1TB SSD) on a PCIE 4.0 slot with up to 3 GB/s read/write speed. Other hardware may yield different results because all analysis are time-bound."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you fail to reproduce any of the results please open a Github issue, if this is left unresponded you can contact me via ljpcvg@gmail.com "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-restricted analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the metadataset for the meta-learners to learn from and to create their result, which can be accessed via the readme. Note that you could also use another metadataset containing information on OpenML18CC datasets to get the results, but these may vary more from what we presented. We assume we already pre-computed characterizations and stored them in the dataset, which can be done as in code example 1 in the readme."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cell contains the code to get the results for one of the meta-learners. Running the cell will vary in length, we have ran them in batches, which is possible via the `dataset_ids` argument in `evaluate()`. Depending on the meta-learning approach each cell may require half a day up to a few days in run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from metadatabase import MetaDataBase\n",
    "from evaluation import LeaveOneDatasetOutEvaluation\n",
    "from metalearners import TopSimilarityLearner, TopXGBoostRanked, UtilityEstimateLearner, AverageRegretLearner, PortfolioBuilding\n",
    "from dataset_characterization import WistubaMetaFeatures, FeurerMetaFeatures, PreTrainedDataset2Vec\n",
    "from configuration_characterization import AlgorithmsPropositionalization, RankMLPipelineRepresentation\n",
    "from dataset_similarity import CharacterizationSimilarity\n",
    "from gama.configuration.classification import clf_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEWARE: <br/>\n",
    "RUNNING THESE CELLS WILL PRODUCE .CSV FILES WITH THE SAME NAMES AS ALREADY PRESENT IN THE ROOT DIR EVALUATION_RESULTS, IT WILL THUS OVERWRITE ALREADY PRESENT RESULTS, CHANGE THE PATH IF YOU WANT TO KEEP BOTH."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"average_regret\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600 # max evaluation time per configuration, thus one dataset may still take 4+ hours, of which we have 72\n",
    "jobs = 1  # n_jobs used in the online phase, typically not the intensive part, the offline phase is\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = AverageRegretLearner()\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                max_time=max_eval_time)\n",
    "\n",
    "# store the evaluation results\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portfolio Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"portfolio_building\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "# load and use pre-computed results matrix, otherwise need to run a 1+ day offline phase 72 times, would be infeasible.\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"portfolio_results_matrix\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = PortfolioBuilding()\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                max_time=max_eval_time)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UtilityEstimate with Wistuba meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"utility_estimate_wistuba\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"wistuba_metafeatures\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = UtilityEstimateLearner(CharacterizationSimilarity(WistubaMetaFeatures()))\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                max_time=max_eval_time)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UtilityEstimate with Feurer meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"utility_estimate_feurer\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"wistuba_metafeatures\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = UtilityEstimateLearner(CharacterizationSimilarity(FeurerMetaFeatures()))\n",
    "\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                max_time=max_eval_time)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UtilityEstimate with Dataset2Vec characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"utility_estimate_d2v\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"dataset2vec_split0_10batches\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = UtilityEstimateLearner(CharacterizationSimilarity(PreTrainedDataset2Vec()))\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                max_time=max_eval_time)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TopSimilarity with Wistuba meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"topsim_wistuba\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"wistuba_metafeatures\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = TopSimilarityLearner(CharacterizationSimilarity(WistubaMetaFeatures()))\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                max_time=max_eval_time)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TopSimilarity with Feurer meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"topsim_feurer\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"feurer_metafeatures\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = TopSimilarityLearner(CharacterizationSimilarity(FeurerMetaFeatures()))\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                max_time=max_eval_time)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TopSimilarity with Dataset2Vec characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"topsim_d2v\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"dataset2vec_split0_10batches\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = TopSimilarityLearner(CharacterizationSimilarity(PreTrainedDataset2Vec()))\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                max_time=max_eval_time)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RankML with Wistuba meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"xgboostranker_rankml_wistuba\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"wistuba_metafeatures\")\n",
    "config_characterizations = mdbase.get_configuration_characterizations(\"rankml_pipeline_representation\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = TopXGBoostRanked(WistubaMetaFeatures(), RankMLPipelineRepresentation(mdbase))\n",
    "metalearner_kwargs = {\"dataset_characterizations_name\": \"wistuba_metafeatures\",\n",
    "                      \"configuration_characterizations_name\": \"rankml_pipeline_representation\",\n",
    "                      \"max_n_models\": 500}  # online phase\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                config_characterizations=config_characterizations,\n",
    "                                                max_time=max_eval_time,\n",
    "                                                metalearner_kwargs=metalearner_kwargs)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RankML with Feurer meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"xgboostranker_rankml_feurer\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"feurer_metafeatures\")\n",
    "config_characterizations = mdbase.get_configuration_characterizations(\"rankml_pipeline_representation\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = TopXGBoostRanked(FeurerMetaFeatures(), RankMLPipelineRepresentation(mdbase))\n",
    "metalearner_kwargs = {\"dataset_characterizations_name\": \"feurer_metafeatures\",\n",
    "                      \"configuration_characterizations_name\": \"rankml_pipeline_representation\",\n",
    "                      \"max_n_models\": 500}  # online phase\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                config_characterizations=config_characterizations,\n",
    "                                                max_time=max_eval_time,\n",
    "                                                metalearner_kwargs=metalearner_kwargs)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RankML with Dataset2Vec characterizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"xgboostranker_rankml_d2v\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"dataset2vec_split0_10batches\")\n",
    "config_characterizations = mdbase.get_configuration_characterizations(\"rankml_pipeline_representation\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = TopXGBoostRanked(PreTrainedDataset2Vec(), RankMLPipelineRepresentation(mdbase))\n",
    "metalearner_kwargs = {\"dataset_characterizations_name\": \"dataset2vec_split0_10batches\",\n",
    "                      \"configuration_characterizations_name\": \"rankml_pipeline_representation\",\n",
    "                      \"max_n_models\": 500}  # online phase\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                config_characterizations=config_characterizations,\n",
    "                                                max_time=max_eval_time,\n",
    "                                                metalearner_kwargs=metalearner_kwargs)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms Propositionalization with Wistuba meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"xgboostranker_ap_wistuba\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"wistuba_metafeatures\")\n",
    "config_characterizations = mdbase.get_configuration_characterizations(\"algorithms_propositionalization\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = TopXGBoostRanked(WistubaMetaFeatures(), AlgorithmsPropositionalization(clf_config))\n",
    "metalearner_kwargs = {\"dataset_characterizations_name\": \"wistuba_metafeatures\",\n",
    "                      \"configuration_characterizations_name\": \"algorithms_propositionalization\",\n",
    "                      \"max_n_models\": 500}  # online phase\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                config_characterizations=config_characterizations,\n",
    "                                                max_time=max_eval_time,\n",
    "                                                metalearner_kwargs=metalearner_kwargs)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms Propositionalization with Feurer meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"xgboostranker_ap_feurer\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"feurer_metafeatures\")\n",
    "config_characterizations = mdbase.get_configuration_characterizations(\"algorithms_propositionalization\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = TopXGBoostRanked(FeurerMetaFeatures(), AlgorithmsPropositionalization(clf_config))\n",
    "metalearner_kwargs = {\"dataset_characterizations_name\": \"feurer_metafeatures\",\n",
    "                      \"configuration_characterizations_name\": \"algorithms_propositionalization\",\n",
    "                      \"max_n_models\": 500}  # online phase\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                config_characterizations=config_characterizations,\n",
    "                                                max_time=max_eval_time,\n",
    "                                                metalearner_kwargs=metalearner_kwargs)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms Propositionalization with Dataset2Vec characterizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_name = \"xgboostranker_ap_d2v\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_eval_time = 600\n",
    "jobs = 1\n",
    "file_name = f\"{meta_learner_name}_{online_phase_time}s.csv\"\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "dataset_characterizations = mdbase.get_dataset_characterizations(\"dataset2vec_split0_10batches\")\n",
    "config_characterizations = mdbase.get_configuration_characterizations(\"algorithms_propositionalization\")\n",
    "\n",
    "evaluation_method = LeaveOneDatasetOutEvaluation(max_time=online_phase_time, n_jobs=jobs)\n",
    "metalearner = TopXGBoostRanked(PreTrainedDataset2Vec(), AlgorithmsPropositionalization(clf_config))\n",
    "metalearner_kwargs = {\"dataset_characterizations_name\": \"dataset2vec_split0_10batches\",\n",
    "                      \"configuration_characterizations_name\": \"algorithms_propositionalization\",\n",
    "                      \"max_n_models\": 500}  # online phase\n",
    "\n",
    "evaluation_results = evaluation_method.evaluate(mdbase,\n",
    "                                                metalearner, \n",
    "                                                dataset_characterizations=dataset_characterizations, \n",
    "                                                config_characterizations=config_characterizations,\n",
    "                                                max_time=max_eval_time,\n",
    "                                                metalearner_kwargs=metalearner_kwargs)\n",
    "\n",
    "store_path = os.path.join(\"evaluation_results\", file_name)\n",
    "evaluation_method.store_results(store_path, meta_learner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-starting analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to reproduce the portfolio building warm-starting results. Note that we ran the evaluation in batches, and we advise you to do the same. Each dataset takes at least 3 hours without re-training and evaluating the best model. Hence a batch of 4 datasets will take 12 hours to run."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEWARE: the full warm-starting analysis will take 216+ hours using 32GB of RAM and 8 threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from utilities import warm_started_gama\n",
    "from metadatabase import MetaDataBase\n",
    "from metalearners import PortfolioBuilding\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from utilities.gama import get_fixed_preprocessing_steps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEWARE: CHANGE BATCH NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in batches, DONT FORGET TO SELECT BATCH\n",
    "batch_1 = [0, 1, 2, 3, 4, 5]  \n",
    "batch_2 = [6, 7, 8]          \n",
    "batch_3 = [9, 10, 11]         \n",
    "batch_4 = [12, 13, 14, 15]    \n",
    "batch_5 = [16, 17, 18, 19]    \n",
    "batch_6 = [20, 21, 22, 23]    \n",
    "batch_7 = [24, 25, 26, 27]    \n",
    "batch_8 = [29, 30, 31]      \n",
    "batch_9 = [33, 34, 35]          \n",
    "batch_10 = [36, 37, 38, 39, 71]\n",
    "batch_11 = [40, 41, 42, 43]     \n",
    "batch_12 = [44, 45, 46, 47]   \n",
    "batch_13 = [48, 49, 50]        \n",
    "batch_14 = [52, 53, 54, 55]    \n",
    "batch_15 = [56, 57, 58, 59]     \n",
    "batch_16 = [60, 61, 62, 63]   \n",
    "batch_17 = [64, 65, 66, 67]   \n",
    "batch_18 = [68, 69, 70]         \n",
    "batch_19 = [28, 32]            \n",
    "batch_20 = [51]                 \n",
    "\n",
    "dataset_ids = batch_1 # TODO TODO TODO ADAPT BATCH EACH RUN TODO TODO TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_name = \"portfolio_building_warm_start_asyncea\"\n",
    "online_phase_time = 300  # in seconds\n",
    "max_gama_time = 3600\n",
    "gama_jobs = 8\n",
    "n_splits = 3\n",
    "\n",
    "mdbase = MetaDataBase(\"metadatabase_openml18cc\")\n",
    "metalearner = PortfolioBuilding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAMA with K-Fold\n",
    "cv_avg = {}\n",
    "for id in dataset_ids:\n",
    "    X, y = mdbase.get_dataset(id)\n",
    "    evaluation_scores = []\n",
    "    # 3 fold CV warm-started GAMA run.\n",
    "    for i, (train_index, test_index) in enumerate(StratifiedKFold(n_splits=n_splits).split(X, y)):\n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = pd.DataFrame(y.iloc[train_index])\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_test = pd.DataFrame(y.iloc[test_index])\n",
    "\n",
    "        datasets_to_keep = mdbase.list_datasets(by=\"id\")\n",
    "        datasets_to_keep.remove(id)\n",
    "        mdbase.partial_datasets_view(datasets_to_keep)  # Do not pass to-be-learned dataset's information to learners offline phase.\n",
    "        results_matrix = mdbase.get_dataset_characterizations(\"portfolio_results_matrix\", include_dimension_names=True)\n",
    "        metalearner.offline_phase(mdbase=mdbase, results_matrix=results_matrix)\n",
    "        \n",
    "        # It could be GAMA does not evaluate any individuals therefore try warm-start, otherwise exclude the run from score computation\n",
    "        try:\n",
    "            gama = warm_started_gama(metalearner, X_train, y_train, online_phase_max_time=online_phase_time, \n",
    "                                    max_total_time=max_gama_time, n_jobs=gama_jobs, logs_path=\"gama_logs/_d{}_f{}\".format(id, i),\n",
    "                                    max_memory_mb=32768)\n",
    "            # get gama's best-evaluated sklearn pipeline\n",
    "            partial_pipe = gama._evaluation_library.n_best(n=1, with_pipelines=True)[0].individual.pipeline\n",
    "            preprocessing_steps = get_fixed_preprocessing_steps(X_train)\n",
    "            pipe_steps = []\n",
    "            for key in partial_pipe.named_steps:\n",
    "                if key != \"imputation\":\n",
    "                    pipe_steps.append((key, partial_pipe.named_steps[key]))\n",
    "            full_best_pipe = Pipeline(preprocessing_steps + pipe_steps)\n",
    "            full_best_pipe.fit(X_train, y_train)\n",
    "\n",
    "            # get the test score, no need to encapsulate with try/except because it was already succesfully fitted in GAMA.\n",
    "            y_pred = full_best_pipe.predict_proba(X_test)\n",
    "            labels = np.unique(LabelEncoder().fit_transform(y))\n",
    "            performance = float(-1 * log_loss(y_true=LabelEncoder().fit_transform(y_test), y_pred=y_pred, labels=labels))\n",
    "            evaluation_scores.append(performance)\n",
    "            mdbase.restore_view()\n",
    "            metalearner.clear_configurations()\n",
    "            print(f\"done with fold: {i}, with a score of: {performance}\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(\"caught ValueError: \", repr(e))\n",
    "            if str(e) == \"population must be at least size 3 for a pair to be selected\":   \n",
    "                print(f\"Had too little individuals in the population for this fold {i}, skip it.\")\n",
    "                mdbase.restore_view()\n",
    "                continue\n",
    "            else:  # only catch the specific ValueError for not enough population, otherwise raise it.\n",
    "                raise e\n",
    "        \n",
    "    \n",
    "    cv_avg[id] = np.mean(evaluation_scores)\n",
    "    print(f\"Dataset with id: {id} attained a score of {cv_avg[id]} at {str(datetime.now())}\")\n",
    "\n",
    "# always write the results to a .csv file with the dataset ids\n",
    "results = []\n",
    "file_name = \"results_\" + approach_name\n",
    "for id in dataset_ids:\n",
    "    file_name += f\"_d{id}\"\n",
    "    score = cv_avg[id]\n",
    "    results.append([f\"{approach_name}\", id, score])\n",
    "\n",
    "warm_start_results_df = pd.DataFrame(np.array(results), columns=['name', 'dataset_name', 'neg_log_loss'])\n",
    "warm_start_results_df.to_csv(file_name + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_no_gama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
