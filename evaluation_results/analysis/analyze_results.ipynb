{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to reproduce the results analysis, e.g. statistical tests and plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook re-creates the statistical tests and figures based on the obtained results -- which are present in this directory. The kernel density and run time figures are created as actual figures (.jpg files), the CD diagrams are outputted as Latex's tikz code, hence to actually visualize the figure you must run it in Latex."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains both the time-restricted analysis on the full and the partial OpenML-CC18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from critdd import Diagram\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the already obtained results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the metadatabase top 25 in a new .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mdbase = pd.read_csv(\"metadatabase_aggregated.csv\")\n",
    "\n",
    "def process_logsname_string(s):\n",
    "    if \"AsynchronousSuccessiveHalving\" in s:\n",
    "        return \"AsynchronousSuccessiveHalving\"\n",
    "    elif \"AsyncEA\" in s:\n",
    "        return \"AsyncEA\"\n",
    "    elif \"RandomSearch\" in s:\n",
    "        return \"RandomSearch\"\n",
    "\n",
    "df_mdbase[\"logs_name\"] = df_mdbase[\"logs_name\"].apply(lambda x : process_logsname_string(x))\n",
    "\n",
    "logs_names = df_mdbase[\"logs_name\"].unique().tolist()\n",
    "dataset_ids = df_mdbase[\"dataset_id\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_select = 25\n",
    "df_total = None\n",
    "\n",
    "for logs_name in logs_names:\n",
    "    for did in dataset_ids:\n",
    "        missing_entry_val = min(df_mdbase[(df_mdbase[\"dataset_id\"] == did) & (df_mdbase[\"score\"] < 1000000)][\"score\"]) - 0.01\n",
    "        df_learner_dataset = df_mdbase[(df_mdbase[\"logs_name\"] == logs_name) & (df_mdbase[\"dataset_id\"] == did)]\n",
    "        df_learner_dataset.reset_index(inplace=True, drop=True)\n",
    "        df_top25 = df_learner_dataset.iloc[[i for i in range(0, min(n_select, len(df_learner_dataset)))]]\n",
    "        if df_total is None:\n",
    "            df_total = df_top25\n",
    "        else:\n",
    "            df_total = pd.concat([df_total, df_top25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total[[\"logs_name\", \"dataset_id\", \"score\"]]\n",
    "df_total.to_csv(\"mdbase_top25.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get mdbase data in correct format -- full OpenML18CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the CD diagram I should still pick only 1 evaluation per meta-learner-dataset\n",
    "\n",
    "df_mdbase = pd.read_csv(\"../results_backup/metadatabase_aggregated.csv\")\n",
    "\n",
    "def process_logsname_string(s):\n",
    "    if \"AsynchronousSuccessiveHalving\" in s:\n",
    "        return \"AsynchronousSuccessiveHalving\"\n",
    "    elif \"AsyncEA\" in s:\n",
    "        return \"AsyncEA\"\n",
    "    elif \"RandomSearch\" in s:\n",
    "        return \"RandomSearch\"\n",
    "\n",
    "df_mdbase[\"logs_name\"] = df_mdbase[\"logs_name\"].apply(lambda x : process_logsname_string(x))\n",
    "\n",
    "logs_names = df_mdbase[\"logs_name\"].unique().tolist()\n",
    "dataset_ids = df_mdbase[\"dataset_id\"].unique().tolist()\n",
    "\n",
    "n_select = 5 # number to select from\n",
    "\n",
    "idx_to_keep = []\n",
    "rows_to_add = []\n",
    "for logs_name in logs_names:\n",
    "    for did in dataset_ids:\n",
    "        missing_entry_val = min(df_mdbase[(df_mdbase[\"dataset_id\"] == did) & (df_mdbase[\"score\"] < 1000000)][\"score\"]) - 0.01\n",
    "        df_learner_dataset = df_mdbase[(df_mdbase[\"logs_name\"] == logs_name) & (df_mdbase[\"dataset_id\"] == did)]\n",
    "        df_learner_dataset.reset_index(inplace=True)\n",
    "        if len(df_learner_dataset) == 0:\n",
    "            rows_to_add.append([logs_name, did, missing_entry_val])\n",
    "        else:\n",
    "            idx_max = df_learner_dataset.iloc[[i for i in range(0, min(n_select, len(df_learner_dataset)))]][\"score\"].idxmax()\n",
    "            if not isinstance(idx_max, np.int64):  # no valid entries for the combo\n",
    "                rows_to_add.append([logs_name, did, missing_entry_val])\n",
    "            else:\n",
    "                idx_to_keep.append(df_learner_dataset.iloc[idx_max][\"index\"])\n",
    "\n",
    "# select idx and add rows for missing entries\n",
    "df_top5 = df_mdbase.iloc[idx_to_keep][[\"logs_name\", \"dataset_id\", \"score\"]]\n",
    "n = len(df_mdbase)\n",
    "for row in rows_to_add:\n",
    "    df_top5.loc[n] = row\n",
    "    n += 1\n",
    "\n",
    "df_top5.to_csv(\"mdbase_baselines_processed.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get mdbase data in correct format -- partial OpenML18CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the CD diagram I should still pick only 1 evaluation per meta-learner-dataset\n",
    "\n",
    "df_mdbase = pd.read_csv(\"../results_backup/metadatabase_aggregated.csv\")\n",
    "openmlcc18_subset_dids = [59, 47, 31, 71, 25, 26, 29, 32, 28, 33, 60, 58, 21, 39, 30, 70, 4, 6, 8, 65, 3, 49, 64, 52, 46, 19, 56, 66, 42, 45, 43, 24, 35, 53, 27, 63, 67, 68]\n",
    "df_mdbase = df_mdbase[df_mdbase[\"dataset_id\"].isin(openmlcc18_subset_dids)]\n",
    "df_mdbase.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def process_logsname_string(s):\n",
    "    if \"AsynchronousSuccessiveHalving\" in s:\n",
    "        return \"AsynchronousSuccessiveHalving\"\n",
    "    elif \"AsyncEA\" in s:\n",
    "        return \"AsyncEA\"\n",
    "    elif \"RandomSearch\" in s:\n",
    "        return \"RandomSearch\"\n",
    "\n",
    "df_mdbase[\"logs_name\"] = df_mdbase[\"logs_name\"].apply(lambda x : process_logsname_string(x))\n",
    "\n",
    "logs_names = df_mdbase[\"logs_name\"].unique().tolist()\n",
    "dataset_ids = df_mdbase[\"dataset_id\"].unique().tolist()\n",
    "\n",
    "n_select = 5 # number to select from\n",
    "\n",
    "idx_to_keep = []\n",
    "rows_to_add = []\n",
    "for logs_name in logs_names:\n",
    "    for did in dataset_ids:\n",
    "        missing_entry_val = min(df_mdbase[(df_mdbase[\"dataset_id\"] == did) & (df_mdbase[\"score\"] < 1000000)][\"score\"]) - 0.01\n",
    "        df_learner_dataset = df_mdbase[(df_mdbase[\"logs_name\"] == logs_name) & (df_mdbase[\"dataset_id\"] == did)]\n",
    "        df_learner_dataset.reset_index(inplace=True)\n",
    "        if len(df_learner_dataset) == 0:\n",
    "            rows_to_add.append([logs_name, did, missing_entry_val])\n",
    "        else:\n",
    "            idx_max = df_learner_dataset.iloc[[i for i in range(0, min(n_select, len(df_learner_dataset)))]][\"score\"].idxmax()\n",
    "            if not isinstance(idx_max, np.int64):  # no valid entries for the combo\n",
    "                rows_to_add.append([logs_name, did, missing_entry_val])\n",
    "            else:\n",
    "                idx_to_keep.append(df_learner_dataset.iloc[idx_max][\"index\"])\n",
    "\n",
    "# select idx and add rows for missing entries\n",
    "df_top5 = df_mdbase.iloc[idx_to_keep][[\"logs_name\", \"dataset_id\", \"score\"]]\n",
    "n = len(df_mdbase)\n",
    "for row in rows_to_add:\n",
    "    df_top5.loc[n] = row\n",
    "    n += 1\n",
    "\n",
    "df_top5.to_csv(\"mdbase_baselines_processed_partial_openmlcc18.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get meta-learner data in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the CD diagram I should still pick only 1 evaluation per meta-learner-dataset\n",
    "df_all = pd.read_csv(\"time_restricted_results_no_dataset2vec.csv\")\n",
    "\n",
    "metalearners = df_all[\"metalearner_name\"].unique().tolist()\n",
    "dataset_ids = df_all[\"dataset_id\"].unique().tolist()\n",
    "\n",
    "n_select = 5 # number to select from\n",
    "\n",
    "idx_to_keep = []\n",
    "rows_to_add = []\n",
    "for metalearner in metalearners:\n",
    "    for did in dataset_ids:\n",
    "        # filter out nan with selection: < 1000000\n",
    "        missing_entry_val = min(df_all[(df_all[\"dataset_id\"] == did) & (df_all[\"neg_log_loss\"] < 1000000)][\"neg_log_loss\"]) - 0.01\n",
    "        df_learner_dataset = df_all[(df_all[\"metalearner_name\"] == metalearner) & (df_all[\"dataset_id\"] == did)]\n",
    "        df_learner_dataset.reset_index(inplace=True)\n",
    "        if len(df_learner_dataset) == 0:\n",
    "            rows_to_add.append([metalearner, did, missing_entry_val])\n",
    "        else:\n",
    "            idx_max = df_learner_dataset.iloc[[i for i in range(0, min(n_select, len(df_learner_dataset)))]][\"neg_log_loss\"].idxmax()\n",
    "            if not isinstance(idx_max, np.int64):  # no valid entries for the combo\n",
    "                rows_to_add.append([metalearner, did, missing_entry_val])\n",
    "            else:\n",
    "                idx_to_keep.append(df_learner_dataset.iloc[idx_max][\"index\"])\n",
    "\n",
    "# select idx and add rows for missing entries\n",
    "df_top5 = df_all.iloc[idx_to_keep]\n",
    "n = len(df_all)\n",
    "for row in rows_to_add:\n",
    "    df_top5.loc[n] = row\n",
    "    n += 1\n",
    "\n",
    "df_top5.to_csv(\"time_restricted_results_no_dataset2vec_processed.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get meta-learner data in correct format -- subset OpenML-CC18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the CD diagram I should still pick only 1 evaluation per meta-learner-dataset\n",
    "df_all = pd.read_csv(\"time_restricted_results.csv\")\n",
    "openmlcc18_subset_dids = [59, 47, 31, 71, 25, 26, 29, 32, 28, 33, 60, 58, 21, 39, 30, 70, 4, 6, 8, 65, 3, 49, 64, 52, 46, 19, 56, 66, 42, 45, 43, 24, 35, 53, 27, 63, 67, 68]\n",
    "df_all = df_all[df_all[\"dataset_id\"].isin(openmlcc18_subset_dids)]\n",
    "df_all.reset_index(drop=True, inplace=True)\n",
    "\n",
    "metalearners = df_all[\"metalearner_name\"].unique().tolist()\n",
    "dataset_ids = df_all[\"dataset_id\"].unique().tolist()\n",
    "\n",
    "n_select = 5 # number to select from\n",
    "\n",
    "idx_to_keep = []\n",
    "rows_to_add = []\n",
    "for metalearner in metalearners:\n",
    "    for did in dataset_ids:\n",
    "        # filter out nan with selection: < 1000000\n",
    "        missing_entry_val = min(df_all[(df_all[\"dataset_id\"] == did) & (df_all[\"neg_log_loss\"] < 1000000)][\"neg_log_loss\"]) - 0.01\n",
    "        df_learner_dataset = df_all[(df_all[\"metalearner_name\"] == metalearner) & (df_all[\"dataset_id\"] == did)]\n",
    "        df_learner_dataset.reset_index(inplace=True)\n",
    "        if len(df_learner_dataset) == 0:\n",
    "            rows_to_add.append([metalearner, did, missing_entry_val])\n",
    "        else:\n",
    "            idx_max = df_learner_dataset.iloc[[i for i in range(0, min(n_select, len(df_learner_dataset)))]][\"neg_log_loss\"].idxmax()\n",
    "            if not isinstance(idx_max, np.int64):  # no valid entries for the combo\n",
    "                rows_to_add.append([metalearner, did, missing_entry_val])\n",
    "            else:\n",
    "                idx_to_keep.append(df_learner_dataset.iloc[idx_max][\"index\"])\n",
    "\n",
    "# select idx and add rows for missing entries\n",
    "df_top5 = df_all.iloc[idx_to_keep]\n",
    "n = len(df_all)\n",
    "for row in rows_to_add:\n",
    "    df_top5.loc[n] = row\n",
    "    n += 1\n",
    "\n",
    "df_top5.to_csv(\"time_restricted_results_processed_partial_openmlcc18.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friedman test, before CD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full OpenML-CC18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "results_df = pd.read_csv(\"time_restricted_results_no_dataset2vec_processed_with_baselines.csv\")\n",
    "results_df[\"neg_log_loss\"] = results_df[\"neg_log_loss\"].astype(float)\n",
    "groups = []\n",
    "\n",
    "for metalearner in list(results_df[\"metalearner_name\"].value_counts().index):\n",
    "    partial_df = results_df[results_df[\"metalearner_name\"] == metalearner]\n",
    "    groups.append(list(partial_df[\"neg_log_loss\"]))\n",
    "\n",
    "#perform Friedman Test\n",
    "stats.friedmanchisquare(*groups)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for OpenML-CC18 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "results_df = pd.read_csv(\"time_restricted_results_processed_partial_openmlcc18_with_baselines.csv\")\n",
    "results_df[\"neg_log_loss\"] = results_df[\"neg_log_loss\"].astype(float)\n",
    "groups = []\n",
    "\n",
    "for metalearner in list(results_df[\"metalearner_name\"].value_counts().index):\n",
    "    partial_df = results_df[results_df[\"metalearner_name\"] == metalearner]\n",
    "    groups.append(list(partial_df[\"neg_log_loss\"]))\n",
    "\n",
    "#perform Friedman Test\n",
    "stats.friedmanchisquare(*groups)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CD Diagrams for time-restricted analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from critdd import Diagram\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"time_restricted_results_no_dataset2vec_processed_with_baselines.csv\").pivot(\n",
    "    index = \"dataset_id\",\n",
    "    columns = \"metalearner_name\",\n",
    "    values = \"neg_log_loss\"\n",
    ")\n",
    "\n",
    "# create a CD diagram from the Pandas DataFrame\n",
    "diagram = Diagram(\n",
    "    df.to_numpy(),\n",
    "    treatment_names = df.columns,\n",
    "    maximize_outcome = True\n",
    ")\n",
    "\n",
    "# inspect average ranks and groups of statistically indistinguishable treatments\n",
    "diagram.average_ranks # the average rank of each treatment\n",
    "diagram.get_groups(alpha=.05, adjustment=\"bonferroni\")\n",
    "\n",
    "# export the diagram to a file\n",
    "diagram.to_file(\n",
    "    \"cd_full_openmlcc18.tex\",\n",
    "    alpha = .05,\n",
    "    adjustment = \"bonferroni\",\n",
    "    reverse_x = True,\n",
    "    axis_options = {\"title\": \"critdd\"},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for OpenML-CC18 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from critdd import Diagram\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"time_restricted_results_processed_partial_openmlcc18_with_baselines.csv\").pivot(\n",
    "    index = \"dataset_id\",\n",
    "    columns = \"metalearner_name\",\n",
    "    values = \"neg_log_loss\"\n",
    ")\n",
    "\n",
    "# create a CD diagram from the Pandas DataFrame\n",
    "diagram = Diagram(\n",
    "    df.to_numpy(),\n",
    "    treatment_names = df.columns,\n",
    "    maximize_outcome = True\n",
    ")\n",
    "\n",
    "# inspect average ranks and groups of statistically indistinguishable treatments\n",
    "diagram.average_ranks # the average rank of each treatment\n",
    "diagram.get_groups(alpha=.05, adjustment=\"bonferroni\")\n",
    "\n",
    "# export the diagram to a file\n",
    "diagram.to_file(\n",
    "    \"cd_partial_openmlcc18.tex\",\n",
    "    alpha = .05,\n",
    "    adjustment = \"bonferroni\",\n",
    "    reverse_x = True,\n",
    "    axis_options = {\"title\": \"critdd\"},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the Average Regret and SD of recommended configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"time_restricted_results.csv\")\n",
    "metalearner_subset = [mtl_name for mtl_name in df_all[\"metalearner_name\"].unique().tolist() if not \"2v\" in mtl_name]\n",
    "df_all = df_all[df_all[\"metalearner_name\"].isin(metalearner_subset)]\n",
    "df_all.reset_index(drop=True, inplace=True)\n",
    "df_all.to_csv(\"time_restricted_results_no_dataset2vec.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out getting the potential score\n",
    "df = pd.read_csv(\"time_restricted_results_no_dataset2vec.csv\")\n",
    "\n",
    "metalearners = df[\"metalearner_name\"].unique().tolist()\n",
    "dataset_ids = df[\"dataset_id\"].unique().tolist()\n",
    "\n",
    "n_recommendation = 25\n",
    "\n",
    "def regret(score):\n",
    "    if score < 100000: # filter out NAN\n",
    "        return abs(max_score - score) / abs(min_score - max_score)\n",
    "    return 1\n",
    "\n",
    "idx_to_keep = []\n",
    "rows_to_add = []\n",
    "metalearner_potential = {}\n",
    "metalearner_std = {}\n",
    "for metalearner in metalearners:\n",
    "    metalearner_dataset_potentials = []\n",
    "    metalearner_dataset_potentials_std = []\n",
    "    for did in dataset_ids:\n",
    "        # filter out nan with selection: < 1000000\n",
    "        missing_entry_val = min(df[(df[\"dataset_id\"] == did) & (df[\"neg_log_loss\"] < 1000000)][\"neg_log_loss\"]) - 0.01\n",
    "        df_did = df[df[\"dataset_id\"] == did]\n",
    "        did_losses_without_nan = [df_did.iloc[i][\"neg_log_loss\"] for i in range(0, len(df_did)) if df_did.iloc[i][\"neg_log_loss\"] < 1_000_000] # comparison to exclude nans\n",
    "        min_score = min(did_losses_without_nan)  \n",
    "        max_score = max(did_losses_without_nan) \n",
    "\n",
    "        df_learner_dataset = df[(df[\"metalearner_name\"] == metalearner) & (df[\"dataset_id\"] == did)]\n",
    "        df_learner_dataset[\"potential\"] = df_learner_dataset[\"neg_log_loss\"].apply(lambda score: regret(score))\n",
    "\n",
    "        # fill the remaining spots, without recommendations with worst regret score: 1\n",
    "        for i in range(len(df_learner_dataset), n_recommendation):\n",
    "            df_learner_dataset.loc[i] = [metalearner, did, missing_entry_val, 1]\n",
    "        \n",
    "        # compute potential for metalearner on this dataset\n",
    "        metalearner_dataset_potentials.append(df_learner_dataset[\"potential\"].mean())\n",
    "        metalearner_dataset_potentials_std.append(df_learner_dataset[\"potential\"].std())\n",
    "\n",
    "    mtl_potential = sum(metalearner_dataset_potentials)/len(metalearner_dataset_potentials)\n",
    "    mtl_std = sum(metalearner_dataset_potentials_std)/len(metalearner_dataset_potentials_std)\n",
    "    metalearner_potential[metalearner] = mtl_potential\n",
    "    metalearner_std[metalearner] = mtl_std\n",
    "    print(f\"metalearner {metalearner} has a potential score of {metalearner_potential}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalearner_potential # regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalearner_std # standard deviation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and potential scores for OpenML-CC18 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the time_restricted_results_partial_openmlcc18.csv\n",
    "df_all = pd.read_csv(\"time_restricted_results.csv\")\n",
    "openmlcc18_subset_dids = [59, 47, 31, 71, 25, 26, 29, 32, 28, 33, 60, 58, 21, 39, 30, 70, 4, 6, 8, 65, 3, 49, 64, 52, 46, 19, 56, 66, 42, 45, 43, 24, 35, 53, 27, 63, 67, 68]\n",
    "df_all = df_all[df_all[\"dataset_id\"].isin(openmlcc18_subset_dids)]\n",
    "df_all.reset_index(drop=True, inplace=True)\n",
    "df_all.to_csv(\"time_restricted_results_partial_openmlcc18.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out getting the potential score\n",
    "df = pd.read_csv(\"time_restricted_results_partial_openmlcc18.csv\")\n",
    "\n",
    "metalearners = df[\"metalearner_name\"].unique().tolist()\n",
    "dataset_ids = df[\"dataset_id\"].unique().tolist()\n",
    "\n",
    "n_recommendation = 25\n",
    "\n",
    "def regret(score):\n",
    "    if score < 100000: # filter out NAN\n",
    "        return abs(max_score - score) / abs(min_score - max_score)\n",
    "    return 1\n",
    "\n",
    "idx_to_keep = []\n",
    "rows_to_add = []\n",
    "metalearner_potential = {}\n",
    "metalearner_std = {}\n",
    "for metalearner in metalearners:\n",
    "    metalearner_dataset_potentials = []\n",
    "    metalearner_dataset_potentials_std = []\n",
    "    for did in dataset_ids:\n",
    "        # filter out nan with selection: < 1000000\n",
    "        missing_entry_val = min(df[(df[\"dataset_id\"] == did) & (df[\"neg_log_loss\"] < 1000000)][\"neg_log_loss\"]) - 0.01\n",
    "        df_did = df[df[\"dataset_id\"] == did]\n",
    "        did_losses_without_nan = [df_did.iloc[i][\"neg_log_loss\"] for i in range(0, len(df_did)) if df_did.iloc[i][\"neg_log_loss\"] < 1_000_000] # comparison to exclude nans\n",
    "        min_score = min(did_losses_without_nan)  \n",
    "        max_score = max(did_losses_without_nan) \n",
    "\n",
    "        df_learner_dataset = df[(df[\"metalearner_name\"] == metalearner) & (df[\"dataset_id\"] == did)]\n",
    "        df_learner_dataset[\"potential\"] = df_learner_dataset[\"neg_log_loss\"].apply(lambda score: regret(score))\n",
    "\n",
    "        # fill the remaining spots, without recommendations with worst regret score: 1\n",
    "        for i in range(len(df_learner_dataset), n_recommendation):\n",
    "            df_learner_dataset.loc[i] = [metalearner, did, missing_entry_val, 1]\n",
    "        \n",
    "        # compute potential for metalearner on this dataset\n",
    "        metalearner_dataset_potentials.append(df_learner_dataset[\"potential\"].mean())\n",
    "        metalearner_dataset_potentials_std.append(df_learner_dataset[\"potential\"].std())\n",
    "\n",
    "    mtl_potential = sum(metalearner_dataset_potentials)/len(metalearner_dataset_potentials)\n",
    "    mtl_std = sum(metalearner_dataset_potentials_std)/len(metalearner_dataset_potentials_std)\n",
    "    metalearner_potential[metalearner] = mtl_potential\n",
    "    metalearner_std[metalearner] = mtl_std\n",
    "    print(f\"metalearner {metalearner} has a potential score of {metalearner_potential}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial openml-cc18 regret\n",
    "metalearner_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial openml-cc18 std\n",
    "metalearner_std"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Rank distribution plots time-restricted analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full OpenML-CC18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"time_restricted_results_no_dataset2vec_processed_with_baselines.csv\")\n",
    "results_df[\"neg_log_loss\"] = results_df[\"neg_log_loss\"].astype(float)\n",
    "\n",
    "all_ranks = []\n",
    "for did in results_df[\"dataset_id\"].unique().tolist():\n",
    "    did_df = results_df[results_df[\"dataset_id\"] == did]\n",
    "    metalearners_ranked = did_df.sort_values(by=\"neg_log_loss\", ascending=False)[\"metalearner_name\"].to_list()\n",
    "    dataset_ranks = [(metalearners_ranked[rank - 1], rank) for rank in range(1, len(metalearners_ranked) + 1)]\n",
    "    all_ranks.append(dataset_ranks)\n",
    "\n",
    "all_ranks\n",
    "ranks_per_metalearner = [] # get the ranks now grouped by each meta-learner\n",
    "metalearner_names = results_df[\"metalearner_name\"].unique().tolist()\n",
    "for metalearner in metalearner_names:\n",
    "    metalearner_ranks = []\n",
    "    for did_ranks in all_ranks:\n",
    "        for rank_entry in did_ranks:\n",
    "            if rank_entry[0] == metalearner:\n",
    "                metalearner_ranks.append(rank_entry[1])\n",
    "    ranks_per_metalearner.append(metalearner_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalearner_names = ['ASHA',\n",
    " 'RandomSearch',\n",
    " 'AsyncEA',\n",
    " 'TopSimilarity-Feurer',\n",
    " 'TopSimilarity-Wistuba',\n",
    " 'AP-Feurer',\n",
    " 'AP-Wistuba',\n",
    " 'Rankml-Feurer',\n",
    " 'Rankml-Wistuba',\n",
    " 'UtilityEstimate-Feurer',\n",
    " 'UtilityEstimate-Wistuba',\n",
    " 'PortfolioBuilding',\n",
    " 'AverageRegret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "f.set_figwidth(12)\n",
    "f.set_figheight(2)\n",
    "\n",
    "plt.violinplot(ranks_per_metalearner, showmeans=True, widths=0.8) # labels=metalearner_names\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel(\"Dataset ranks\")\n",
    "ax.set_xticklabels(metalearner_names)\n",
    "ax.set_xticks([i + 1 for i in range(0, len(metalearner_names))])\n",
    "ax.tick_params(axis='x', labelrotation = -70)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial OpenML-CC18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"time_restricted_results_no_dataset2vec_processed_with_baselines.csv\")\n",
    "results_df[\"neg_log_loss\"] = results_df[\"neg_log_loss\"].astype(float)\n",
    "\n",
    "all_ranks = []\n",
    "for did in results_df[\"dataset_id\"].unique().tolist():\n",
    "    did_df = results_df[results_df[\"dataset_id\"] == did]\n",
    "    metalearners_ranked = did_df.sort_values(by=\"neg_log_loss\", ascending=False)[\"metalearner_name\"].to_list()\n",
    "    dataset_ranks = [(metalearners_ranked[rank - 1], rank) for rank in range(1, len(metalearners_ranked) + 1)]\n",
    "    all_ranks.append(dataset_ranks)\n",
    "\n",
    "all_ranks\n",
    "ranks_per_metalearner = [] # get the ranks now grouped by each meta-learner\n",
    "metalearner_names = results_df[\"metalearner_name\"].unique().tolist()\n",
    "for metalearner in metalearner_names:\n",
    "    metalearner_ranks = []\n",
    "    for did_ranks in all_ranks:\n",
    "        for rank_entry in did_ranks:\n",
    "            if rank_entry[0] == metalearner:\n",
    "                metalearner_ranks.append(rank_entry[1])\n",
    "    ranks_per_metalearner.append(metalearner_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalearner_names = ['ASHA',\n",
    " 'RandomSearch',\n",
    " 'AsyncEA',\n",
    " 'TopSimilarity-Feurer',\n",
    " 'TopSimilarity-Wistuba',\n",
    " 'TopSimilarity-D2V',\n",
    " 'AP-Feurer',\n",
    " 'AP-Wistuba',\n",
    " 'AP-D2V',\n",
    " 'AP-D2V',\n",
    " 'Rankml-Feurer',\n",
    " 'Rankml-Wistuba',\n",
    " 'Rankml-D2V',\n",
    " 'UtilityEstimate-Feurer',\n",
    " 'UtilityEstimate-Wistuba',\n",
    " 'UtilityEstimate-D2V',\n",
    " 'PortfolioBuilding',\n",
    " 'AverageRegret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "f.set_figwidth(12)\n",
    "f.set_figheight(2)\n",
    "\n",
    "plt.violinplot(ranks_per_metalearner, showmeans=True, widths=0.8) # labels=metalearner_names\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel(\"Dataset ranks\")\n",
    "ax.set_xticklabels(metalearner_names)\n",
    "ax.set_xticks([i + 1 for i in range(0, len(metalearner_names))])\n",
    "ax.tick_params(axis='x', labelrotation = -70)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timings for the dataset characterizations measures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process the available timings, e.g. get in better format to create plots from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# process timings\n",
    "filename = \"feurer_timings_raw.txt\"\n",
    "with open(filename) as file:\n",
    "    lines = [line.rstrip().split(\" at \")[1] for line in file]\n",
    "feurer_datetimes = [datetime.strptime(line, '%Y-%m-%d %H:%M:%S.%f') for line in lines]\n",
    "feurer_time_difs = [(feurer_datetimes[i + 1] - feurer_datetimes[i]).total_seconds() for i in range(0, len(feurer_datetimes) - 1)]\n",
    "feurer_dataset_timings = {}\n",
    "for i, time_dif in enumerate(feurer_time_difs):\n",
    "    feurer_dataset_timings[i] = time_dif\n",
    "\n",
    "filename = \"wistuba_timings_raw.txt\"\n",
    "with open(filename) as file:\n",
    "    lines = [line.rstrip().split(\" at \")[1] for line in file]\n",
    "wistuba_datetimes = [datetime.strptime(line, '%Y-%m-%d %H:%M:%S.%f') for line in lines]\n",
    "wistuba_time_difs = [(wistuba_datetimes[i + 1] - wistuba_datetimes[i]).total_seconds() for i in range(0, len(wistuba_datetimes) - 1)]\n",
    "wistuba_dataset_timings = {}\n",
    "for i, time_dif in enumerate(wistuba_time_difs):\n",
    "    wistuba_dataset_timings[i] = time_dif\n",
    "\n",
    "filename = \"dataset2vec_timings_raw.txt\"\n",
    "with open(filename) as file:\n",
    "    lines = [line.rstrip().split(\" at \")[1] for line in file]\n",
    "d2v_datetimes = [datetime.strptime(line, '%Y-%m-%d %H:%M:%S.%f') for line in lines]\n",
    "d2v_time_difs = [(d2v_datetimes[i + 1] - d2v_datetimes[i]).total_seconds() for i in range(0, len(d2v_datetimes) - 1)]\n",
    "d2v_dataset_timings = {}\n",
    "for i, time_dif in enumerate(d2v_time_difs):\n",
    "    d2v_dataset_timings[i] = time_dif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets ordered by samples, features, outcomes. Needed for plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets ordered by samples, features, outcomes\n",
    "did_n_samples =  {71: 500, 31: 522, 50: 540, 59: 540, 36: 569, 41: 583, 2: 625, 11: 690, 5: 699, 21: 736, 48: 748, 14: 768, 26: 797, 25: 841, 18: 846, 17: 958, 23: 990, 12: 1000, 37: 1055, 45: 1080, 58: 1080, 33: 1109, 47: 1372, 28: 1458, 9: 1473, 29: 1563, 40: 1593, 61: 1728, 57: 1941, 3: 2000, 4: 2000, 6: 2000, 7: 2000, 8: 2000, 65: 2000, 32: 2109, 62: 2310, 44: 2534, 42: 2600, 69: 3186, 16: 3190, 0: 3196, 56: 3279, 35: 3751, 22: 3772, 15: 4601, 60: 4839, 70: 5000, 39: 5404, 38: 5456, 54: 5500, 10: 5620, 46: 6118, 20: 6430, 24: 7797, 52: 9873, 53: 10299, 30: 10885, 13: 10992, 49: 11055, 1: 20000, 43: 34465, 64: 44819, 51: 45211, 19: 45312, 34: 48842, 68: 60000, 55: 67557, 27: 70000, 63: 70000, 67: 92000, 66: 96320}\n",
    "did_n_features =  {2: 4, 26: 4, 47: 4, 48: 4, 39: 5, 60: 5, 7: 6, 61: 6, 64: 6, 14: 8, 19: 8, 5: 9, 9: 9, 17: 9, 41: 10, 23: 12, 71: 12, 34: 14, 11: 15, 1: 16, 13: 16, 51: 16, 18: 18, 21: 19, 62: 19, 12: 20, 59: 20, 70: 20, 30: 21, 31: 21, 32: 21, 33: 21, 66: 21, 38: 24, 57: 27, 22: 29, 36: 30, 49: 30, 52: 32, 0: 36, 20: 36, 28: 37, 29: 37, 50: 39, 54: 40, 37: 41, 55: 42, 8: 47, 46: 51, 15: 57, 16: 61, 6: 64, 10: 64, 25: 70, 44: 72, 4: 76, 58: 81, 43: 118, 69: 180, 3: 216, 65: 240, 40: 256, 42: 500, 53: 561, 24: 617, 27: 784, 63: 784, 45: 856, 67: 1024, 56: 1558, 35: 1776, 68: 3072}\n",
    "did_n_outcomes =  {0: 2, 5: 2, 11: 2, 12: 2, 14: 2, 15: 2, 17: 2, 19: 2, 22: 2, 28: 2, 29: 2, 30: 2, 31: 2, 32: 2, 33: 2, 34: 2, 35: 2, 36: 2, 37: 2, 39: 2, 41: 2, 42: 2, 43: 2, 44: 2, 47: 2, 48: 2, 49: 2, 50: 2, 51: 2, 56: 2, 59: 2, 60: 2, 66: 2, 70: 2, 71: 2, 2: 3, 9: 3, 16: 3, 55: 3, 64: 3, 69: 3, 18: 4, 25: 4, 38: 4, 61: 4, 21: 5, 52: 5, 65: 5, 20: 6, 26: 6, 46: 6, 53: 6, 57: 7, 62: 7, 58: 8, 45: 9, 3: 10, 4: 10, 6: 10, 7: 10, 8: 10, 10: 10, 13: 10, 27: 10, 40: 10, 63: 10, 68: 10, 23: 11, 54: 11, 1: 26, 24: 26, 67: 46}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actually create the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, sharex=False, sharey=False, figsize=(10, 8))\n",
    "\n",
    "import numpy as np\n",
    "x = np.random.rand(10)\n",
    "y = np.random.rand(10)\n",
    "z = np.sqrt(x**2 + y**2)\n",
    "\n",
    "# D2V n_samples\n",
    "x = list(did_n_samples.values())\n",
    "y = [d2v_dataset_timings[did] for did in did_n_samples.keys()]\n",
    "axs[0, 0].scatter(x, y, color=\"tab:blue\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[0, 0].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[0, 0].set_xticks([])\n",
    "for i, id in enumerate(list(did_n_samples.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 56 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[0, 0].annotate(\" \" + str(id), (x[i], y[i] - 7))\n",
    "        else:\n",
    "            axs[0, 0].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[0, 0].set_title(\"\\n # Samples\")\n",
    "axs[0, 0].set_ylabel(\"time (seconds)\")\n",
    "\n",
    "# D2V n_features\n",
    "x = list(did_n_features.values())\n",
    "y = [d2v_dataset_timings[did] for did in did_n_features.keys()]\n",
    "axs[0, 1].scatter(x, y, color=\"tab:orange\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[0, 1].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[0, 1].set_xticks([])\n",
    "axs[0, 1].set_yticks([])\n",
    "for i, id in enumerate(list(did_n_features.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 56 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[0, 1].annotate(\" \" + str(id), (x[i], y[i] - 7))\n",
    "        else:\n",
    "            axs[0, 1].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[0, 1].set_title(\"Dataset2Vec \\n# Features\")\n",
    "\n",
    "# D2V n_outcomes\n",
    "x = list(did_n_outcomes.values())\n",
    "y = [d2v_dataset_timings[did] for did in did_n_outcomes.keys()]\n",
    "axs[0, 2].scatter(x, y, color=\"tab:green\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[0, 2].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[0, 2].set_title(\"\\n # Outcomes\")\n",
    "axs[0, 2].set_xticks([])\n",
    "axs[0, 2].set_yticks([])\n",
    "for i, id in enumerate(list(did_n_outcomes.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 56 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[0, 2].annotate(\" \" + str(id), (x[i], y[i] - 7))\n",
    "        else:\n",
    "            axs[0, 2].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "\n",
    "# Feurer n_samples\n",
    "x = list(did_n_samples.values())\n",
    "y = [feurer_dataset_timings[did] for did in did_n_samples.keys()]\n",
    "axs[1, 0].scatter(x, y, color=\"tab:blue\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[1, 0].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[1, 0].set_xticks([])\n",
    "for i, id in enumerate(list(did_n_samples.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[1, 0].annotate(\" \" + str(id), (x[i], y[i] - 1000))\n",
    "        else:\n",
    "            axs[1, 0].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[1, 0].set_ylabel(\"time (seconds)\")\n",
    "\n",
    "# Feurer n_features\n",
    "x = list(did_n_features.values())\n",
    "y = [feurer_dataset_timings[did] for did in did_n_features.keys()]\n",
    "axs[1, 1].scatter(x, y, color=\"tab:orange\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[1, 1].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[1, 1].set_xticks([])\n",
    "axs[1, 1].set_yticks([])\n",
    "for i, id in enumerate(list(did_n_features.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[1, 1].annotate(\" \" + str(id), (x[i], y[i] - 1000))\n",
    "        else:\n",
    "            axs[1, 1].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[1, 1].set_title(\"Feurer MF\")\n",
    "\n",
    "# Feurer n_outcomes\n",
    "x = list(did_n_outcomes.values())\n",
    "y = [feurer_dataset_timings[did] for did in did_n_outcomes.keys()]\n",
    "axs[1, 2].scatter(x, y, color=\"tab:green\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[1, 2].set_xticks([])\n",
    "axs[1, 2].set_yticks([])\n",
    "for i, id in enumerate(list(did_n_outcomes.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[1, 2].annotate(\" \" + str(id), (x[i], y[i] - 1000))\n",
    "        else:\n",
    "            axs[1, 2].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[1, 2].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "\n",
    "# Wistuba n_samples\n",
    "x = list(did_n_samples.values())\n",
    "y = [wistuba_dataset_timings[did] for did in did_n_samples.keys()]\n",
    "axs[2, 0].scatter(x, y, color=\"tab:blue\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[2, 0].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "for i, id in enumerate(list(did_n_samples.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[2, 0].annotate(\" \" + str(id), (x[i], y[i] - 50))\n",
    "        else:\n",
    "            axs[2, 0].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[2, 0].set_ylabel(\"time (seconds)\")\n",
    "\n",
    "# Wistuba n_features\n",
    "x = list(did_n_features.values())\n",
    "y = [wistuba_dataset_timings[did] for did in did_n_features.keys()]\n",
    "axs[2, 1].scatter(x, y, color=\"tab:orange\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[2, 1].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[2, 1].set_yticks([])\n",
    "for i, id in enumerate(list(did_n_features.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[2, 1].annotate(\" \" + str(id), (x[i], y[i] - 50))\n",
    "        else:\n",
    "            axs[2, 1].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[2, 1].set_title(\"Wistuba MF\")\n",
    "\n",
    "# Wistuba n_outcomes\n",
    "x = list(did_n_outcomes.values())\n",
    "y = [wistuba_dataset_timings[did] for did in did_n_outcomes.keys()]\n",
    "axs[2, 2].scatter(x, y, color=\"tab:green\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[2, 2].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[2, 2].set_yticks([])\n",
    "for i, id in enumerate(list(did_n_outcomes.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[2, 2].annotate(\" \" + str(id), (x[i], y[i] - 50))\n",
    "        else:\n",
    "            axs[2, 2].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets ordered by samples, features, outcomes. But now excluding the annotated datasets (e.g. the outliers) Needed for plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets ordered by samples, features, outcomes\n",
    "did_n_samples =  {71: 500, 31: 522, 50: 540, 59: 540, 36: 569, 41: 583, 2: 625, 11: 690, 5: 699, 21: 736, 48: 748, 14: 768, 26: 797, 25: 841, 18: 846, 17: 958, 23: 990, 12: 1000, 37: 1055, 45: 1080, 58: 1080, 33: 1109, 47: 1372, 28: 1458, 9: 1473, 29: 1563, 40: 1593, 61: 1728, 57: 1941, 3: 2000, 4: 2000, 6: 2000, 7: 2000, 8: 2000, 65: 2000, 32: 2109, 62: 2310, 44: 2534, 42: 2600, 69: 3186, 16: 3190, 0: 3196, 35: 3751, 22: 3772, 15: 4601, 60: 4839, 70: 5000, 39: 5404, 38: 5456, 54: 5500, 10: 5620, 46: 6118, 20: 6430, 24: 7797, 52: 9873, 53: 10299, 30: 10885, 13: 10992, 49: 11055, 1: 20000, 43: 34465, 64: 44819, 51: 45211, 19: 45312, 34: 48842, 55: 67557, 66: 96320}\n",
    "did_n_features =  {2: 4, 26: 4, 47: 4, 48: 4, 39: 5, 60: 5, 7: 6, 61: 6, 64: 6, 14: 8, 19: 8, 5: 9, 9: 9, 17: 9, 41: 10, 23: 12, 71: 12, 34: 14, 11: 15, 1: 16, 13: 16, 51: 16, 18: 18, 21: 19, 62: 19, 12: 20, 59: 20, 70: 20, 30: 21, 31: 21, 32: 21, 33: 21, 66: 21, 38: 24, 57: 27, 22: 29, 36: 30, 49: 30, 52: 32, 0: 36, 20: 36, 28: 37, 29: 37, 50: 39, 54: 40, 37: 41, 55: 42, 8: 47, 46: 51, 15: 57, 16: 61, 6: 64, 10: 64, 25: 70, 44: 72, 4: 76, 58: 81, 43: 118, 69: 180, 3: 216, 65: 240, 40: 256, 42: 500, 53: 561, 24: 617, 45: 856, 35: 1776}\n",
    "did_n_outcomes =  {0: 2, 5: 2, 11: 2, 12: 2, 14: 2, 15: 2, 17: 2, 19: 2, 22: 2, 28: 2, 29: 2, 30: 2, 31: 2, 32: 2, 33: 2, 34: 2, 35: 2, 36: 2, 37: 2, 39: 2, 41: 2, 42: 2, 43: 2, 44: 2, 47: 2, 48: 2, 49: 2, 50: 2, 51: 2, 59: 2, 60: 2, 66: 2, 70: 2, 71: 2, 2: 3, 9: 3, 16: 3, 55: 3, 64: 3, 69: 3, 18: 4, 25: 4, 38: 4, 61: 4, 21: 5, 52: 5, 65: 5, 20: 6, 26: 6, 46: 6, 53: 6, 57: 7, 62: 7, 58: 8, 45: 9, 3: 10, 4: 10, 6: 10, 7: 10, 8: 10, 10: 10, 13: 10, 40: 10, 23: 11, 54: 11, 1: 26, 24: 26}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the plot without the annotated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, sharex=False, sharey=False, figsize=(10, 8))\n",
    "\n",
    "import numpy as np\n",
    "x = np.random.rand(10)\n",
    "y = np.random.rand(10)\n",
    "z = np.sqrt(x**2 + y**2)\n",
    "\n",
    "# D2V n_samples\n",
    "x = list(did_n_samples.values())\n",
    "y = [d2v_dataset_timings[did] for did in did_n_samples.keys()]\n",
    "axs[0, 0].scatter(x, y, color=\"tab:blue\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[0, 0].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[0, 0].set_xticks([])\n",
    "for i, id in enumerate(list(did_n_samples.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 56 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[0, 0].annotate(\" \" + str(id), (x[i], y[i] - 7))\n",
    "        else:\n",
    "            axs[0, 0].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[0, 0].set_title(\"\\n # Samples\")\n",
    "axs[0, 0].set_ylabel(\"time (seconds)\")\n",
    "\n",
    "# D2V n_features\n",
    "x = list(did_n_features.values())\n",
    "y = [d2v_dataset_timings[did] for did in did_n_features.keys()]\n",
    "axs[0, 1].scatter(x, y, color=\"tab:orange\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[0, 1].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[0, 1].set_xticks([])\n",
    "axs[0, 1].set_yticks([])\n",
    "for i, id in enumerate(list(did_n_features.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 56 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[0, 1].annotate(\" \" + str(id), (x[i], y[i] - 7))\n",
    "        else:\n",
    "            axs[0, 1].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[0, 1].set_title(\"Dataset2Vec \\n# Features\")\n",
    "\n",
    "# D2V n_outcomes\n",
    "x = list(did_n_outcomes.values())\n",
    "y = [d2v_dataset_timings[did] for did in did_n_outcomes.keys()]\n",
    "axs[0, 2].scatter(x, y, color=\"tab:green\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[0, 2].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[0, 2].set_title(\"\\n # Outcomes\")\n",
    "axs[0, 2].set_xticks([])\n",
    "axs[0, 2].set_yticks([])\n",
    "for i, id in enumerate(list(did_n_outcomes.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 56 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[0, 2].annotate(\" \" + str(id), (x[i], y[i] - 7))\n",
    "        else:\n",
    "            axs[0, 2].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "\n",
    "# Feurer n_samples\n",
    "x = list(did_n_samples.values())\n",
    "y = [feurer_dataset_timings[did] for did in did_n_samples.keys()]\n",
    "axs[1, 0].scatter(x, y, color=\"tab:blue\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[1, 0].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[1, 0].set_xticks([])\n",
    "for i, id in enumerate(list(did_n_samples.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[1, 0].annotate(\" \" + str(id), (x[i], y[i] - 1000))\n",
    "        else:\n",
    "            axs[1, 0].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[1, 0].set_ylabel(\"time (seconds)\")\n",
    "\n",
    "# Feurer n_features\n",
    "x = list(did_n_features.values())\n",
    "y = [feurer_dataset_timings[did] for did in did_n_features.keys()]\n",
    "axs[1, 1].scatter(x, y, color=\"tab:orange\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[1, 1].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[1, 1].set_xticks([])\n",
    "axs[1, 1].set_yticks([])\n",
    "for i, id in enumerate(list(did_n_features.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[1, 1].annotate(\" \" + str(id), (x[i], y[i] - 1000))\n",
    "        else:\n",
    "            axs[1, 1].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[1, 1].set_title(\"Feurer MF\")\n",
    "\n",
    "# Feurer n_outcomes\n",
    "x = list(did_n_outcomes.values())\n",
    "y = [feurer_dataset_timings[did] for did in did_n_outcomes.keys()]\n",
    "axs[1, 2].scatter(x, y, color=\"tab:green\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[1, 2].set_xticks([])\n",
    "axs[1, 2].set_yticks([])\n",
    "for i, id in enumerate(list(did_n_outcomes.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 27:\n",
    "        if id != 63:\n",
    "            axs[1, 2].annotate(\" \" + str(id), (x[i], y[i] - 1000))\n",
    "        else:\n",
    "            axs[1, 2].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[1, 2].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "\n",
    "# Wistuba n_samples\n",
    "x = list(did_n_samples.values())\n",
    "y = [wistuba_dataset_timings[did] for did in did_n_samples.keys()]\n",
    "axs[2, 0].scatter(x, y, color=\"tab:blue\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[2, 0].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "for i, id in enumerate(list(did_n_samples.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 27:\n",
    "        axs[2, 0].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[2, 0].set_ylabel(\"time (seconds)\")\n",
    "\n",
    "# Wistuba n_features\n",
    "x = list(did_n_features.values())\n",
    "y = [wistuba_dataset_timings[did] for did in did_n_features.keys()]\n",
    "axs[2, 1].scatter(x, y, color=\"tab:orange\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[2, 1].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[2, 1].set_yticks([])\n",
    "for i, id in enumerate(list(did_n_features.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 27:\n",
    "        axs[2, 1].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "axs[2, 1].set_title(\"Wistuba MF\")\n",
    "\n",
    "# Wistuba n_outcomes\n",
    "x = list(did_n_outcomes.values())\n",
    "y = [wistuba_dataset_timings[did] for did in did_n_outcomes.keys()]\n",
    "axs[2, 2].scatter(x, y, color=\"tab:green\")\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "xseq = np.linspace(0, max(x), num=100)\n",
    "axs[2, 2].plot(xseq, a + b * xseq, color=\"k\", lw=1) # Plot regression line\n",
    "axs[2, 2].set_yticks([])\n",
    "for i, id in enumerate(list(did_n_outcomes.keys())):\n",
    "    if id == 68 or id == 67 or id == 63 or id == 27:\n",
    "        axs[2, 2].annotate(\" \" + str(id), (x[i], y[i]))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for warm-starting analysis\n",
    "Can perform these on the full OpenML-CC18 collection because no Dataset2Vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Friedman test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FriedmanchisquareResult(statistic=67.84453781512607, pvalue=1.2351188524471527e-14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_csv(\"warm_starting_with_baselines.csv\")\n",
    "results_df[\"neg_log_loss\"] = results_df[\"neg_log_loss\"].astype(float)\n",
    "groups = []\n",
    "\n",
    "for metalearner in list(results_df[\"metalearner_name\"].value_counts().index):\n",
    "    partial_df = results_df[results_df[\"metalearner_name\"] == metalearner]\n",
    "    groups.append(list(partial_df[\"neg_log_loss\"]))\n",
    "\n",
    "#perform Friedman Test\n",
    "stats.friedmanchisquare(*groups)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CD diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leigh\\miniconda3\\envs\\thesis_results\\Lib\\site-packages\\scipy\\stats\\_morestats.py:3414: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    }
   ],
   "source": [
    "from critdd import Diagram\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"warm_starting_with_baselines.csv\").pivot(\n",
    "    index = \"dataset_id\",\n",
    "    columns = \"metalearner_name\",\n",
    "    values = \"neg_log_loss\"\n",
    ")\n",
    "\n",
    "# create a CD diagram from the Pandas DataFrame\n",
    "diagram = Diagram(\n",
    "    df.to_numpy(),\n",
    "    treatment_names = df.columns,\n",
    "    maximize_outcome = True\n",
    ")\n",
    "\n",
    "# inspect average ranks and groups of statistically indistinguishable treatments\n",
    "diagram.average_ranks # the average rank of each treatment\n",
    "diagram.get_groups(alpha=.05, adjustment=\"bonferroni\")\n",
    "\n",
    "# export the diagram to a file\n",
    "diagram.to_file(\n",
    "    \"cd_warm_starting_openmlcc18.tex\",\n",
    "    alpha = .05,\n",
    "    adjustment = \"bonferroni\",\n",
    "    reverse_x = True,\n",
    "    axis_options = {\"title\": \"critdd\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.051393011661874,\n",
       "  -0.1228700174932168,\n",
       "  -0.0071171718133126,\n",
       "  -0.1004290770911031,\n",
       "  -0.440720112426924,\n",
       "  -0.0863528957983473,\n",
       "  -0.1301593007457853,\n",
       "  -0.6181317321817076,\n",
       "  -0.3807043835336944,\n",
       "  -0.8960588731953962,\n",
       "  -0.0704605184552923,\n",
       "  -0.3462688228944105,\n",
       "  -0.4865738433796213,\n",
       "  -0.0324878209539063,\n",
       "  -0.4632236164274056,\n",
       "  -0.1838840422862409,\n",
       "  -0.0332900884174255,\n",
       "  -0.1237475178392572,\n",
       "  -0.371312444956044,\n",
       "  -0.5557034253818508,\n",
       "  -0.2223275992040469,\n",
       "  -0.9290295200441598,\n",
       "  -0.0217705627729129,\n",
       "  -1.085803556616585,\n",
       "  -0.1408052063403321,\n",
       "  -0.0184666075377894,\n",
       "  -1.7488814183357124,\n",
       "  -0.297591391915455,\n",
       "  -0.1838413697332203,\n",
       "  -0.2451339317227712,\n",
       "  -0.4465599573781905,\n",
       "  -0.389387559433825,\n",
       "  -0.3544527191990674,\n",
       "  -0.1975810874735099,\n",
       "  -0.2783857208019186,\n",
       "  -0.4424410558113675,\n",
       "  -0.0752308261670886,\n",
       "  -0.3202932770826899,\n",
       "  -0.0320128062531775,\n",
       "  -0.2144568590109129,\n",
       "  -0.192382688939165,\n",
       "  -0.5089133152809241,\n",
       "  -0.3835405103632012,\n",
       "  -0.1357895733112867,\n",
       "  -0.1598319990078411,\n",
       "  -0.1455352046845575,\n",
       "  -1.2482366844008497,\n",
       "  -2.220446049250313e-16,\n",
       "  -0.4849670189855305,\n",
       "  -0.0873179774775469,\n",
       "  -0.6506073959857994,\n",
       "  -0.3187440277913433,\n",
       "  -1.2734744805985696,\n",
       "  -0.1323823648106012,\n",
       "  -0.0099880487515315,\n",
       "  -0.8447395292570621,\n",
       "  -0.13187729953085,\n",
       "  -0.9731688231676188,\n",
       "  -1.5543122344752201e-15,\n",
       "  -0.1226086848045188,\n",
       "  -0.0406967841825152,\n",
       "  -0.4203114318035504,\n",
       "  -0.0581805385292257,\n",
       "  -0.4404865363522168,\n",
       "  -0.7137365545419675,\n",
       "  -0.2008809808425791,\n",
       "  -0.6921391222013423,\n",
       "  -3.602562823791632,\n",
       "  -2.115928199784241,\n",
       "  -0.1117351356055354,\n",
       "  -0.1576382488964552,\n",
       "  -0.6604117817368035],\n",
       " [-0.0603598477141138,\n",
       "  -0.142557638321006,\n",
       "  -0.0114798413811031,\n",
       "  -0.1010074956186223,\n",
       "  -0.4542275663768393,\n",
       "  -0.0851059727073657,\n",
       "  -0.1480073623669179,\n",
       "  -0.6154606967814049,\n",
       "  -0.4270291871477599,\n",
       "  -0.8966602416682733,\n",
       "  -0.0764067848410052,\n",
       "  -0.3529310045441237,\n",
       "  -0.4847935968096207,\n",
       "  -0.0359502673329709,\n",
       "  -0.4641908075733059,\n",
       "  -0.1821070946053304,\n",
       "  -0.032731382391205,\n",
       "  -0.1260744857693111,\n",
       "  -0.4186556920337622,\n",
       "  -0.5333863543764094,\n",
       "  -0.2235990627221367,\n",
       "  -0.9337189790799972,\n",
       "  -0.026625867180519,\n",
       "  -1.0818774584651645,\n",
       "  -0.152817670942094,\n",
       "  -0.0144517590554283,\n",
       "  -1.7460155916364055,\n",
       "  -0.2849560271385828,\n",
       "  -0.1866961829895032,\n",
       "  -0.247887918587752,\n",
       "  -0.4463570556958384,\n",
       "  -0.3864089304226245,\n",
       "  -0.355511098994676,\n",
       "  -0.1968930064230544,\n",
       "  -0.2827269880303281,\n",
       "  -0.4502711608280183,\n",
       "  -0.0789804161613213,\n",
       "  -0.3243406050225562,\n",
       "  -0.0304461424577506,\n",
       "  -0.226382077370041,\n",
       "  -0.1986280615318154,\n",
       "  -0.5097332884478277,\n",
       "  -0.3773567635717693,\n",
       "  -0.148075574129671,\n",
       "  -0.1597604339139642,\n",
       "  -0.1727532133762516,\n",
       "  -1.2554014319100473,\n",
       "  -2.220446049250313e-16,\n",
       "  -0.4731803515957755,\n",
       "  -0.0902706426366384,\n",
       "  -0.6323871656185837,\n",
       "  -0.3020651495586645,\n",
       "  -1.264774172699726,\n",
       "  -0.167169392346707,\n",
       "  -0.0199817386441906,\n",
       "  -0.7520755372817199,\n",
       "  -0.1331461055419753,\n",
       "  -0.980915719599676,\n",
       "  -1.5543122344752201e-15,\n",
       "  -0.1241329760915707,\n",
       "  -0.0405486825822373,\n",
       "  -0.4195959417655961,\n",
       "  -0.0611123319402532,\n",
       "  -0.8004695400710915,\n",
       "  -0.6995046166138577,\n",
       "  -0.2106241930539862,\n",
       "  -0.691626567448127,\n",
       "  -3.1363626671443376,\n",
       "  -2.5822346444565127,\n",
       "  -0.1139913575085406,\n",
       "  -0.1607427799978562,\n",
       "  -0.6527380246833726],\n",
       " [-0.052785054165467,\n",
       "  -0.1115294316307894,\n",
       "  -0.0052569245628442,\n",
       "  -0.1010074955341978,\n",
       "  -0.3928420329197977,\n",
       "  -0.0824094646591117,\n",
       "  -0.1385570843206056,\n",
       "  -0.6502311536676665,\n",
       "  -0.3561252718141299,\n",
       "  -0.8889481221341219,\n",
       "  -0.0629309409361197,\n",
       "  -0.3584035576407817,\n",
       "  -0.4832255272043295,\n",
       "  -0.0332193823463912,\n",
       "  -0.4645579814807955,\n",
       "  -0.1751012673265796,\n",
       "  -0.0776153583404554,\n",
       "  -0.1225316488862446,\n",
       "  -0.3770616441051936,\n",
       "  -0.520236983453162,\n",
       "  -0.2164076534712911,\n",
       "  -0.9318500671789494,\n",
       "  -0.021862503380529,\n",
       "  -1.0122594352738865,\n",
       "  -0.1390504796265851,\n",
       "  -0.008699625647629,\n",
       "  -1.742273994507443,\n",
       "  -0.2936926709096102,\n",
       "  -0.1784882154007256,\n",
       "  -0.2424673327365675,\n",
       "  -0.4449991558023073,\n",
       "  -0.3902700739173926,\n",
       "  -0.3527738798626891,\n",
       "  -0.194749669047711,\n",
       "  -0.2761574449133172,\n",
       "  -0.4402464962708648,\n",
       "  -0.0692066495787523,\n",
       "  -0.315439090164167,\n",
       "  -0.0288571824410573,\n",
       "  -0.2254531081192221,\n",
       "  -0.2561643681870287,\n",
       "  -0.5072808636446149,\n",
       "  -0.3556391937793344,\n",
       "  -0.1319271377174826,\n",
       "  -0.1589323164627833,\n",
       "  -0.1455352046845575,\n",
       "  -1.250191159710686,\n",
       "  -1.0883466786865533e-07,\n",
       "  -0.4728054780836597,\n",
       "  -0.0924590757664784,\n",
       "  -0.6113028977661513,\n",
       "  -0.2797611312658284,\n",
       "  -1.261575426593241,\n",
       "  -0.1389131752406349,\n",
       "  -0.0087752951518842,\n",
       "  -0.7766055114679261,\n",
       "  -0.1275702572695359,\n",
       "  -0.955160517016348,\n",
       "  -1.5543122344752201e-15,\n",
       "  -0.1245780321713367,\n",
       "  -0.0394426028812364,\n",
       "  -0.3881436599249827,\n",
       "  -0.0543581087361181,\n",
       "  -0.7867892176641349,\n",
       "  -0.673828082856239,\n",
       "  -0.2000668753698516,\n",
       "  -0.6915922124853366,\n",
       "  -2.888627093535156,\n",
       "  -2.164498081514989,\n",
       "  -0.1038128004840101,\n",
       "  -0.1518130085252981,\n",
       "  -0.658837607965818],\n",
       " [-0.2004443692700356,\n",
       "  -0.1334462597617734,\n",
       "  -0.012671162224556,\n",
       "  -0.1107584927263957,\n",
       "  -0.4265002153512308,\n",
       "  -0.10767435590654,\n",
       "  -0.1224542685754727,\n",
       "  -0.8437329979906831,\n",
       "  -0.3868785462398236,\n",
       "  -0.9163278114636256,\n",
       "  -0.0786768082096584,\n",
       "  -0.4193260890737906,\n",
       "  -0.4829085091785702,\n",
       "  -0.0469163756198692,\n",
       "  -0.4743102870530092,\n",
       "  -0.1779334114947162,\n",
       "  -18.640026012747484,\n",
       "  -2.7136000659470625,\n",
       "  -0.4516167913069961,\n",
       "  -0.5668344908465076,\n",
       "  -0.2342861055039704,\n",
       "  -1.2339144711721346,\n",
       "  -0.0231443984271172,\n",
       "  -1.0714222045646902,\n",
       "  -0.1391678205782035,\n",
       "  -0.0239881841927785,\n",
       "  -1.7700751633499712,\n",
       "  -0.2847339878436963,\n",
       "  -0.2297783452002673,\n",
       "  -0.2777863601589754,\n",
       "  -0.4520991436828575,\n",
       "  -0.5206397494093866,\n",
       "  -0.3677612099516413,\n",
       "  -0.2984032694832959,\n",
       "  -0.2768850853140325,\n",
       "  -0.4536414381529428,\n",
       "  -0.1150060180783591,\n",
       "  -0.389047807061751,\n",
       "  -0.0357543307249101,\n",
       "  -0.2358239842650595,\n",
       "  -0.1887114679314558,\n",
       "  -0.5538388420059358,\n",
       "  -0.3834147170135542,\n",
       "  -0.1413011009070981,\n",
       "  -0.1986458431767557,\n",
       "  -0.1669915028559936,\n",
       "  -1.3612123939644132,\n",
       "  -0.0043791772913974,\n",
       "  -0.5306493750775456,\n",
       "  -0.1244158061854821,\n",
       "  -0.8660273314331084,\n",
       "  -0.3120651495586645,\n",
       "  -1.3336060643756065,\n",
       "  -0.1371144241553944,\n",
       "  -0.0238637585604809,\n",
       "  -0.6913962513323909,\n",
       "  -0.1512118614694632,\n",
       "  -1.180992199475045,\n",
       "  -7.842831987446789,\n",
       "  -0.1584407800266619,\n",
       "  -0.0420692304893937,\n",
       "  -0.6700590714663001,\n",
       "  -0.066964559632062,\n",
       "  -0.4172795103872033,\n",
       "  -0.7867892176641349,\n",
       "  -0.2493295932760815,\n",
       "  -0.6915018759563447,\n",
       "  -2.553654637214605,\n",
       "  -1.762820849634994,\n",
       "  -0.1154496402698071,\n",
       "  -0.1562401194258381,\n",
       "  -0.6963195405255626]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=2, sharex=True, subplot_kw=dict(frameon=False), figsize=(16, 8),height_ratios=[3, 1]) # frameon=False removes frames\n",
    "# plt.subplots_adjust(hspace=.0)\n",
    "# ax1 = fig.add_subplot(111)\n",
    "\n",
    "# exclude datasets with 58 and 16 because outliers\n",
    "warm_start_errs = groups[3]\n",
    "warm_start_errs[58] = None\n",
    "warm_start_errs[16] = None\n",
    "\n",
    "datasets = [i for i in range(0, 72)]\n",
    "ax1.scatter(datasets, groups[0], s=25, c='blue', marker=\"*\", alpha=0.2, label='ASHA')\n",
    "ax1.scatter(datasets, groups[1], s=25, c='black', marker=\"o\", alpha=0.2, label='RandomSearch')\n",
    "ax1.scatter(datasets, groups[2], s=25, c='green', marker=\"x\", alpha=1, label='AsyncEA')\n",
    "ax1.scatter(datasets, groups[3], s=25, c='red', marker=\"$W$\", alpha=1, label='warm-started AsyncEA')\n",
    "# ax1.set_yscale(\"symlog\")\n",
    "ax1.legend()\n",
    "\n",
    "# ax2 = fig.add_subplot(212)\n",
    "# datasets ordered by samples, features, outcomes\n",
    "did_n_samples =  {71: 500, 31: 522, 50: 540, 59: 540, 36: 569, 41: 583, 2: 625, 11: 690, 5: 699, 21: 736, 48: 748, 14: 768, 26: 797, 25: 841, 18: 846, 17: 958, 23: 990, 12: 1000, 37: 1055, 45: 1080, 58: 1080, 33: 1109, 47: 1372, 28: 1458, 9: 1473, 29: 1563, 40: 1593, 61: 1728, 57: 1941, 3: 2000, 4: 2000, 6: 2000, 7: 2000, 8: 2000, 65: 2000, 32: 2109, 62: 2310, 44: 2534, 42: 2600, 69: 3186, 16: 3190, 0: 3196, 56: 3279, 35: 3751, 22: 3772, 15: 4601, 60: 4839, 70: 5000, 39: 5404, 38: 5456, 54: 5500, 10: 5620, 46: 6118, 20: 6430, 24: 7797, 52: 9873, 53: 10299, 30: 10885, 13: 10992, 49: 11055, 1: 20000, 43: 34465, 64: 44819, 51: 45211, 19: 45312, 34: 48842, 68: 60000, 55: 67557, 27: 70000, 63: 70000, 67: 92000, 66: 96320}\n",
    "did_n_features =  {2: 4, 26: 4, 47: 4, 48: 4, 39: 5, 60: 5, 7: 6, 61: 6, 64: 6, 14: 8, 19: 8, 5: 9, 9: 9, 17: 9, 41: 10, 23: 12, 71: 12, 34: 14, 11: 15, 1: 16, 13: 16, 51: 16, 18: 18, 21: 19, 62: 19, 12: 20, 59: 20, 70: 20, 30: 21, 31: 21, 32: 21, 33: 21, 66: 21, 38: 24, 57: 27, 22: 29, 36: 30, 49: 30, 52: 32, 0: 36, 20: 36, 28: 37, 29: 37, 50: 39, 54: 40, 37: 41, 55: 42, 8: 47, 46: 51, 15: 57, 16: 61, 6: 64, 10: 64, 25: 70, 44: 72, 4: 76, 58: 81, 43: 118, 69: 180, 3: 216, 65: 240, 40: 256, 42: 500, 53: 561, 24: 617, 27: 784, 63: 784, 45: 856, 67: 1024, 56: 1558, 35: 1776, 68: 3072}\n",
    "did_n_outcomes =  {0: 2, 5: 2, 11: 2, 12: 2, 14: 2, 15: 2, 17: 2, 19: 2, 22: 2, 28: 2, 29: 2, 30: 2, 31: 2, 32: 2, 33: 2, 34: 2, 35: 2, 36: 2, 37: 2, 39: 2, 41: 2, 42: 2, 43: 2, 44: 2, 47: 2, 48: 2, 49: 2, 50: 2, 51: 2, 56: 2, 59: 2, 60: 2, 66: 2, 70: 2, 71: 2, 2: 3, 9: 3, 16: 3, 55: 3, 64: 3, 69: 3, 18: 4, 25: 4, 38: 4, 61: 4, 21: 5, 52: 5, 65: 5, 20: 6, 26: 6, 46: 6, 53: 6, 57: 7, 62: 7, 58: 8, 45: 9, 3: 10, 4: 10, 6: 10, 7: 10, 8: 10, 10: 10, 13: 10, 27: 10, 40: 10, 63: 10, 68: 10, 23: 11, 54: 11, 1: 26, 24: 26, 67: 46}\n",
    "\n",
    "did_n_values = {}\n",
    "datasets_ids = [i for i in range(0, 72)]\n",
    "for did in datasets_ids:\n",
    "    did_n_values[did] = did_n_samples[did] * (did_n_features[did] + did_n_outcomes[did])\n",
    "ax2.bar(datasets_ids, list(did_n_values.values()))\n",
    "ax2.set_xticks([]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # datasets ordered by samples, features, outcomes\n",
    "# did_n_samples =  {71: 500, 31: 522, 50: 540, 59: 540, 36: 569, 41: 583, 2: 625, 11: 690, 5: 699, 21: 736, 48: 748, 14: 768, 26: 797, 25: 841, 18: 846, 17: 958, 23: 990, 12: 1000, 37: 1055, 45: 1080, 58: 1080, 33: 1109, 47: 1372, 28: 1458, 9: 1473, 29: 1563, 40: 1593, 61: 1728, 57: 1941, 3: 2000, 4: 2000, 6: 2000, 7: 2000, 8: 2000, 65: 2000, 32: 2109, 62: 2310, 44: 2534, 42: 2600, 69: 3186, 16: 3190, 0: 3196, 56: 3279, 35: 3751, 22: 3772, 15: 4601, 60: 4839, 70: 5000, 39: 5404, 38: 5456, 54: 5500, 10: 5620, 46: 6118, 20: 6430, 24: 7797, 52: 9873, 53: 10299, 30: 10885, 13: 10992, 49: 11055, 1: 20000, 43: 34465, 64: 44819, 51: 45211, 19: 45312, 34: 48842, 68: 60000, 55: 67557, 27: 70000, 63: 70000, 67: 92000, 66: 96320}\n",
    "# did_n_features =  {2: 4, 26: 4, 47: 4, 48: 4, 39: 5, 60: 5, 7: 6, 61: 6, 64: 6, 14: 8, 19: 8, 5: 9, 9: 9, 17: 9, 41: 10, 23: 12, 71: 12, 34: 14, 11: 15, 1: 16, 13: 16, 51: 16, 18: 18, 21: 19, 62: 19, 12: 20, 59: 20, 70: 20, 30: 21, 31: 21, 32: 21, 33: 21, 66: 21, 38: 24, 57: 27, 22: 29, 36: 30, 49: 30, 52: 32, 0: 36, 20: 36, 28: 37, 29: 37, 50: 39, 54: 40, 37: 41, 55: 42, 8: 47, 46: 51, 15: 57, 16: 61, 6: 64, 10: 64, 25: 70, 44: 72, 4: 76, 58: 81, 43: 118, 69: 180, 3: 216, 65: 240, 40: 256, 42: 500, 53: 561, 24: 617, 27: 784, 63: 784, 45: 856, 67: 1024, 56: 1558, 35: 1776, 68: 3072}\n",
    "# did_n_outcomes =  {0: 2, 5: 2, 11: 2, 12: 2, 14: 2, 15: 2, 17: 2, 19: 2, 22: 2, 28: 2, 29: 2, 30: 2, 31: 2, 32: 2, 33: 2, 34: 2, 35: 2, 36: 2, 37: 2, 39: 2, 41: 2, 42: 2, 43: 2, 44: 2, 47: 2, 48: 2, 49: 2, 50: 2, 51: 2, 56: 2, 59: 2, 60: 2, 66: 2, 70: 2, 71: 2, 2: 3, 9: 3, 16: 3, 55: 3, 64: 3, 69: 3, 18: 4, 25: 4, 38: 4, 61: 4, 21: 5, 52: 5, 65: 5, 20: 6, 26: 6, 46: 6, 53: 6, 57: 7, 62: 7, 58: 8, 45: 9, 3: 10, 4: 10, 6: 10, 7: 10, 8: 10, 10: 10, 13: 10, 27: 10, 40: 10, 63: 10, 68: 10, 23: 11, 54: 11, 1: 26, 24: 26, 67: 46}\n",
    "\n",
    "# did_n_values = {}\n",
    "# datasets_ids = [i for i in range(0, 72)]\n",
    "# for did in datasets_ids:\n",
    "#     did_n_values[did] = did_n_samples[did] * (did_n_features[did] + did_n_outcomes[did])\n",
    "\n",
    "# plt.bar(datasets_ids, list(did_n_values.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_gama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
